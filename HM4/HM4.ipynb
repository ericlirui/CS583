{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "HM4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwo98SML1-xV",
        "colab_type": "text"
      },
      "source": [
        "# Home 4: Build a CNN for image recognition.\n",
        "\n",
        "### Name: [RUI LI]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pCND5ea1-xZ",
        "colab_type": "text"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    * Missing **the output after execution** will not be graded.\n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wRisqMp1-xh",
        "colab_type": "text"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9gLX6iW1-xj",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jaYio6_1-xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "edd3c041-9d05-49fe-8c26-802b48aa093e"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ICYypKY1-xu",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V-OsupA1-x0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f024d521-34e4-4008-c537-ebcdc5856ce5"
      },
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "    results = np.zeros((len(y),num_class))\n",
        "    for i, label in enumerate(y):\n",
        "      results[i,label] = 1.\n",
        "    return results\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vujdR8071-yC",
        "colab_type": "text"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFVe6Ucz1-yE",
        "colab_type": "text"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCcEFB7B1-yF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8189e04d-1f53-4eb1-833c-ae92d3f51164"
      },
      "source": [
        "rand_indices = np.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JD7espR1-yU",
        "colab_type": "text"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRZMXYWw1-yW",
        "colab_type": "text"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwaLjf0b1-yX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adeaf56e-073a-48a7-c08d-8fe4c6db4bf3"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(128, (3, 3), padding='same')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_25 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jqUDGn_1-yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "#hyper parameters\n",
        "learning_rate = 1E-3 \n",
        "batch_size = 64\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XieqTTts5gev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "\t\trotation_range=15,\n",
        "\t\twidth_shift_range=0.1,\n",
        "\t\theight_shift_range=0.1,\n",
        "\t\thorizontal_flip=True,)\n",
        "train_datagen.fit(x_tr)\n",
        "train_generator = train_datagen.flow(x_tr, y_tr, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8bVXfKo1-yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9b640c4-a627-43bd-b72e-08162ebda1cd"
      },
      "source": [
        "# fit model\n",
        "# history = model.fit(x_tr, y_tr, batch_size=32, epochs=35, validation_data=(x_val, y_val))\n",
        "steps= int(x_tr.shape[0] / batch_size)\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = steps, epochs = 100, validation_data=(x_val, y_val))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "625/625 [==============================] - 25s 40ms/step - loss: 1.5369 - acc: 0.4392 - val_loss: 1.3185 - val_acc: 0.5462\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 1.1880 - acc: 0.5714 - val_loss: 1.1319 - val_acc: 0.6145\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 1.0519 - acc: 0.6266 - val_loss: 1.2015 - val_acc: 0.6137\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.9672 - acc: 0.6576 - val_loss: 2.1787 - val_acc: 0.3955\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.9094 - acc: 0.6779 - val_loss: 0.9128 - val_acc: 0.6848\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.8607 - acc: 0.6973 - val_loss: 0.8369 - val_acc: 0.7129\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.8264 - acc: 0.7097 - val_loss: 0.9020 - val_acc: 0.7082\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.7988 - acc: 0.7217 - val_loss: 0.8259 - val_acc: 0.7230\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.7753 - acc: 0.7288 - val_loss: 0.8385 - val_acc: 0.7076\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.7501 - acc: 0.7404 - val_loss: 0.7501 - val_acc: 0.7468\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.7355 - acc: 0.7419 - val_loss: 0.7319 - val_acc: 0.7502\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.7176 - acc: 0.7499 - val_loss: 0.7859 - val_acc: 0.7429\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6964 - acc: 0.7592 - val_loss: 0.8463 - val_acc: 0.7147\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6926 - acc: 0.7637 - val_loss: 0.8393 - val_acc: 0.7241\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6758 - acc: 0.7653 - val_loss: 0.7331 - val_acc: 0.7630\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6629 - acc: 0.7719 - val_loss: 0.8320 - val_acc: 0.7391\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6499 - acc: 0.7749 - val_loss: 0.6204 - val_acc: 0.7959\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6459 - acc: 0.7775 - val_loss: 0.7458 - val_acc: 0.7513\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6332 - acc: 0.7835 - val_loss: 0.6175 - val_acc: 0.7945\n",
            "Epoch 20/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6222 - acc: 0.7861 - val_loss: 0.5385 - val_acc: 0.8126\n",
            "Epoch 21/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.6212 - acc: 0.7877 - val_loss: 0.7151 - val_acc: 0.7614\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6095 - acc: 0.7911 - val_loss: 0.6591 - val_acc: 0.7926\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6037 - acc: 0.7930 - val_loss: 0.5599 - val_acc: 0.8076\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.6020 - acc: 0.7938 - val_loss: 0.5473 - val_acc: 0.8178\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5956 - acc: 0.7945 - val_loss: 0.6010 - val_acc: 0.8038\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5785 - acc: 0.8023 - val_loss: 0.5225 - val_acc: 0.8302\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5816 - acc: 0.8006 - val_loss: 0.5731 - val_acc: 0.8117\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5801 - acc: 0.8007 - val_loss: 0.5889 - val_acc: 0.8095\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5705 - acc: 0.8042 - val_loss: 0.5393 - val_acc: 0.8256\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5629 - acc: 0.8075 - val_loss: 0.6887 - val_acc: 0.7830\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5644 - acc: 0.8071 - val_loss: 0.6219 - val_acc: 0.8030\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5598 - acc: 0.8098 - val_loss: 0.4898 - val_acc: 0.8410\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5511 - acc: 0.8105 - val_loss: 0.5789 - val_acc: 0.8065\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5430 - acc: 0.8125 - val_loss: 0.7193 - val_acc: 0.7826\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5452 - acc: 0.8132 - val_loss: 0.5601 - val_acc: 0.8170\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5410 - acc: 0.8146 - val_loss: 0.5959 - val_acc: 0.8064\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5413 - acc: 0.8154 - val_loss: 0.5107 - val_acc: 0.8265\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.5356 - acc: 0.8166 - val_loss: 0.4771 - val_acc: 0.8347\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5345 - acc: 0.8185 - val_loss: 0.4495 - val_acc: 0.8501\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5290 - acc: 0.8194 - val_loss: 0.5464 - val_acc: 0.8270\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5186 - acc: 0.8219 - val_loss: 0.5537 - val_acc: 0.8235\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5185 - acc: 0.8229 - val_loss: 0.6756 - val_acc: 0.7959\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5164 - acc: 0.8237 - val_loss: 0.6399 - val_acc: 0.7957\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5162 - acc: 0.8211 - val_loss: 0.5079 - val_acc: 0.8316\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.5097 - acc: 0.8234 - val_loss: 0.5304 - val_acc: 0.8275\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - 23s 36ms/step - loss: 0.5113 - acc: 0.8246 - val_loss: 0.5565 - val_acc: 0.8259\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5072 - acc: 0.8283 - val_loss: 0.6813 - val_acc: 0.7913\n",
            "Epoch 48/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5054 - acc: 0.8296 - val_loss: 0.4957 - val_acc: 0.8445\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5056 - acc: 0.8253 - val_loss: 0.6352 - val_acc: 0.8074\n",
            "Epoch 50/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5033 - acc: 0.8283 - val_loss: 0.7754 - val_acc: 0.7683\n",
            "Epoch 51/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.5026 - acc: 0.8284 - val_loss: 0.5884 - val_acc: 0.8128\n",
            "Epoch 52/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4989 - acc: 0.8283 - val_loss: 0.6761 - val_acc: 0.7848\n",
            "Epoch 53/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.5001 - acc: 0.8298 - val_loss: 0.6861 - val_acc: 0.7860\n",
            "Epoch 54/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4911 - acc: 0.8308 - val_loss: 0.5512 - val_acc: 0.8239\n",
            "Epoch 55/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4932 - acc: 0.8305 - val_loss: 0.5126 - val_acc: 0.8345\n",
            "Epoch 56/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4910 - acc: 0.8306 - val_loss: 0.4391 - val_acc: 0.8552\n",
            "Epoch 57/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4853 - acc: 0.8332 - val_loss: 0.5665 - val_acc: 0.8206\n",
            "Epoch 58/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4868 - acc: 0.8328 - val_loss: 0.5600 - val_acc: 0.8194\n",
            "Epoch 59/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4872 - acc: 0.8332 - val_loss: 0.4525 - val_acc: 0.8512\n",
            "Epoch 60/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4813 - acc: 0.8356 - val_loss: 0.5606 - val_acc: 0.8213\n",
            "Epoch 61/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4807 - acc: 0.8341 - val_loss: 0.4961 - val_acc: 0.8357\n",
            "Epoch 62/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4807 - acc: 0.8351 - val_loss: 0.4633 - val_acc: 0.8503\n",
            "Epoch 63/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4769 - acc: 0.8371 - val_loss: 0.4437 - val_acc: 0.8553\n",
            "Epoch 64/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4743 - acc: 0.8377 - val_loss: 0.4342 - val_acc: 0.8570\n",
            "Epoch 65/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4731 - acc: 0.8389 - val_loss: 0.4745 - val_acc: 0.8469\n",
            "Epoch 66/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4707 - acc: 0.8375 - val_loss: 0.4933 - val_acc: 0.8455\n",
            "Epoch 67/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4650 - acc: 0.8393 - val_loss: 0.5737 - val_acc: 0.8227\n",
            "Epoch 68/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4680 - acc: 0.8408 - val_loss: 0.4546 - val_acc: 0.8517\n",
            "Epoch 69/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4676 - acc: 0.8378 - val_loss: 0.4576 - val_acc: 0.8524\n",
            "Epoch 70/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4616 - acc: 0.8417 - val_loss: 0.5278 - val_acc: 0.8335\n",
            "Epoch 71/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4647 - acc: 0.8393 - val_loss: 0.4878 - val_acc: 0.8431\n",
            "Epoch 72/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4604 - acc: 0.8413 - val_loss: 0.4958 - val_acc: 0.8428\n",
            "Epoch 73/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4591 - acc: 0.8423 - val_loss: 0.4864 - val_acc: 0.8436\n",
            "Epoch 74/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4554 - acc: 0.8431 - val_loss: 0.4522 - val_acc: 0.8553\n",
            "Epoch 75/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4563 - acc: 0.8410 - val_loss: 0.5241 - val_acc: 0.8356\n",
            "Epoch 76/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4594 - acc: 0.8414 - val_loss: 0.5516 - val_acc: 0.8273\n",
            "Epoch 77/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4510 - acc: 0.8428 - val_loss: 0.4449 - val_acc: 0.8542\n",
            "Epoch 78/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4535 - acc: 0.8448 - val_loss: 0.4288 - val_acc: 0.8619\n",
            "Epoch 79/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4550 - acc: 0.8416 - val_loss: 0.5054 - val_acc: 0.8356\n",
            "Epoch 80/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4504 - acc: 0.8442 - val_loss: 0.5022 - val_acc: 0.8502\n",
            "Epoch 81/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4547 - acc: 0.8439 - val_loss: 0.5441 - val_acc: 0.8377\n",
            "Epoch 82/100\n",
            "625/625 [==============================] - 25s 39ms/step - loss: 0.4465 - acc: 0.8447 - val_loss: 0.4674 - val_acc: 0.8508\n",
            "Epoch 83/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4431 - acc: 0.8482 - val_loss: 0.5007 - val_acc: 0.8386\n",
            "Epoch 84/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4444 - acc: 0.8485 - val_loss: 0.4341 - val_acc: 0.8558\n",
            "Epoch 85/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4434 - acc: 0.8501 - val_loss: 0.4184 - val_acc: 0.8630\n",
            "Epoch 86/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4396 - acc: 0.8498 - val_loss: 0.4714 - val_acc: 0.8503\n",
            "Epoch 87/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4446 - acc: 0.8461 - val_loss: 0.4471 - val_acc: 0.8506\n",
            "Epoch 88/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4376 - acc: 0.8483 - val_loss: 0.4421 - val_acc: 0.8541\n",
            "Epoch 89/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4354 - acc: 0.8502 - val_loss: 0.5368 - val_acc: 0.8354\n",
            "Epoch 90/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4400 - acc: 0.8485 - val_loss: 0.5198 - val_acc: 0.8362\n",
            "Epoch 91/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4342 - acc: 0.8527 - val_loss: 0.4228 - val_acc: 0.8619\n",
            "Epoch 92/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4345 - acc: 0.8506 - val_loss: 0.4446 - val_acc: 0.8537\n",
            "Epoch 93/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4361 - acc: 0.8512 - val_loss: 0.4430 - val_acc: 0.8550\n",
            "Epoch 94/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4298 - acc: 0.8533 - val_loss: 0.4859 - val_acc: 0.8468\n",
            "Epoch 95/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4341 - acc: 0.8524 - val_loss: 0.4480 - val_acc: 0.8543\n",
            "Epoch 96/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4327 - acc: 0.8522 - val_loss: 0.5106 - val_acc: 0.8378\n",
            "Epoch 97/100\n",
            "625/625 [==============================] - 22s 36ms/step - loss: 0.4317 - acc: 0.8513 - val_loss: 0.4996 - val_acc: 0.8451\n",
            "Epoch 98/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4343 - acc: 0.8530 - val_loss: 0.4204 - val_acc: 0.8570\n",
            "Epoch 99/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4276 - acc: 0.8530 - val_loss: 0.4816 - val_acc: 0.8452\n",
            "Epoch 100/100\n",
            "625/625 [==============================] - 22s 35ms/step - loss: 0.4304 - acc: 0.8537 - val_loss: 0.4306 - val_acc: 0.8579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4P9CEiq1-yp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "058e5043-94f2-4da5-b5ba-359cc7e92157"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss= history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.title('Accuracy')\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.title('Cross Entropy Loss')\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4KyAGGMMSYoCxDGGGOC+v+xnBtADG4yCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYWlgdCo1-yr",
        "colab_type": "text"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ84IEZu1-yu",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lfwM24n1-yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#<Compile your model again (using the same hyper-parameters)>\n",
        "#hyper parameters\n",
        "learning_rate = 1E-3 \n",
        "batch_size = 64\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb0h2sFG1-yy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6af9c0d8-f622-47d7-c08b-d9ee334db9b0"
      },
      "source": [
        "#<Train your model on the entire training set (50K samples)>\n",
        "#<Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
        "#<Do NOT use the validation_data option (because now you do not have validation data)>\n",
        "train_datagen.fit(x_train)\n",
        "train_generator = train_datagen.flow(x_train, y_train_vec, batch_size)\n",
        "steps= int(x_train.shape[0] / batch_size)\n",
        "history = model.fit_generator(train_generator, steps_per_epoch = steps, epochs = 100)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.4554 - acc: 0.8452\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4466 - acc: 0.8469\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4441 - acc: 0.8479\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4447 - acc: 0.8487\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4397 - acc: 0.8486\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4411 - acc: 0.8490\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4413 - acc: 0.8487\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4389 - acc: 0.8485\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4361 - acc: 0.8499\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4333 - acc: 0.8510\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4380 - acc: 0.8496\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4341 - acc: 0.8517\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4350 - acc: 0.8510\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4336 - acc: 0.8508\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4332 - acc: 0.8506\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4332 - acc: 0.8512\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4304 - acc: 0.8513\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4253 - acc: 0.8543\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4294 - acc: 0.8535\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4254 - acc: 0.8529\n",
            "Epoch 21/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4221 - acc: 0.8549\n",
            "Epoch 22/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4257 - acc: 0.8546\n",
            "Epoch 23/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4204 - acc: 0.8548\n",
            "Epoch 24/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4218 - acc: 0.8551\n",
            "Epoch 25/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4183 - acc: 0.8583\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4171 - acc: 0.8566\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4200 - acc: 0.8563\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4245 - acc: 0.8549\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4148 - acc: 0.8578\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4181 - acc: 0.8571\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4148 - acc: 0.8574\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4189 - acc: 0.8561\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4204 - acc: 0.8557\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4168 - acc: 0.8586\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4116 - acc: 0.8576\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4165 - acc: 0.8563\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4120 - acc: 0.8583\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4124 - acc: 0.8593\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4129 - acc: 0.8591\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4081 - acc: 0.8592\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4119 - acc: 0.8579\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4065 - acc: 0.8604\n",
            "Epoch 43/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4069 - acc: 0.8598\n",
            "Epoch 44/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4091 - acc: 0.8598\n",
            "Epoch 45/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4028 - acc: 0.8612\n",
            "Epoch 46/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4020 - acc: 0.8635\n",
            "Epoch 47/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4056 - acc: 0.8606\n",
            "Epoch 48/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.4095 - acc: 0.8599\n",
            "Epoch 49/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.3999 - acc: 0.8619\n",
            "Epoch 50/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4071 - acc: 0.8613\n",
            "Epoch 51/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4033 - acc: 0.8609\n",
            "Epoch 52/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3994 - acc: 0.8624\n",
            "Epoch 53/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.4043 - acc: 0.8621\n",
            "Epoch 54/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.4011 - acc: 0.8628\n",
            "Epoch 55/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3978 - acc: 0.8627\n",
            "Epoch 56/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.4000 - acc: 0.8622\n",
            "Epoch 57/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3978 - acc: 0.8652\n",
            "Epoch 58/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.4026 - acc: 0.8607\n",
            "Epoch 59/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3987 - acc: 0.8631\n",
            "Epoch 60/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.4003 - acc: 0.8619\n",
            "Epoch 61/100\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.4029 - acc: 0.8606\n",
            "Epoch 62/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3945 - acc: 0.8641\n",
            "Epoch 63/100\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.4000 - acc: 0.8610\n",
            "Epoch 64/100\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.3949 - acc: 0.8637\n",
            "Epoch 65/100\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.3974 - acc: 0.8625\n",
            "Epoch 66/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3961 - acc: 0.8642\n",
            "Epoch 67/100\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.3936 - acc: 0.8640\n",
            "Epoch 68/100\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.3967 - acc: 0.8650\n",
            "Epoch 69/100\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.3911 - acc: 0.8654\n",
            "Epoch 70/100\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.3922 - acc: 0.8647\n",
            "Epoch 71/100\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.3928 - acc: 0.8650\n",
            "Epoch 72/100\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.3885 - acc: 0.8655\n",
            "Epoch 73/100\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.3926 - acc: 0.8648\n",
            "Epoch 74/100\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.3876 - acc: 0.8669\n",
            "Epoch 75/100\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.3926 - acc: 0.8656\n",
            "Epoch 76/100\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.3892 - acc: 0.8669\n",
            "Epoch 77/100\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.3890 - acc: 0.8667\n",
            "Epoch 78/100\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.3934 - acc: 0.8652\n",
            "Epoch 79/100\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.3872 - acc: 0.8669\n",
            "Epoch 80/100\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.3910 - acc: 0.8656\n",
            "Epoch 81/100\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.3922 - acc: 0.8650\n",
            "Epoch 82/100\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.3886 - acc: 0.8656\n",
            "Epoch 83/100\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.3875 - acc: 0.8667\n",
            "Epoch 84/100\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.3868 - acc: 0.8673\n",
            "Epoch 85/100\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.3891 - acc: 0.8669\n",
            "Epoch 86/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3858 - acc: 0.8665\n",
            "Epoch 87/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3852 - acc: 0.8656\n",
            "Epoch 88/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3883 - acc: 0.8672\n",
            "Epoch 89/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.3878 - acc: 0.8679\n",
            "Epoch 90/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.3815 - acc: 0.8686\n",
            "Epoch 91/100\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.3844 - acc: 0.8673\n",
            "Epoch 92/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.3800 - acc: 0.8706\n",
            "Epoch 93/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.3794 - acc: 0.8687\n",
            "Epoch 94/100\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.3801 - acc: 0.8683\n",
            "Epoch 95/100\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.3835 - acc: 0.8686\n",
            "Epoch 96/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3825 - acc: 0.8687\n",
            "Epoch 97/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3815 - acc: 0.8668\n",
            "Epoch 98/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3796 - acc: 0.8693\n",
            "Epoch 99/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3869 - acc: 0.8659\n",
            "Epoch 100/100\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3821 - acc: 0.8677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJU29NpB1-y0",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdO-0fGM1-y1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "55a23dfd-4cc8-4693-f69b-78856cd40495"
      },
      "source": [
        "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 188us/step\n",
            "loss = 0.42866249833106995\n",
            "accuracy = 0.8649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul8sA13m1-y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}